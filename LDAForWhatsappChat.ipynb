{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDAForWhatsappChat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUns96htIkoIc4twL7zJ0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatihkykc/lda4wpchat/blob/master/LDAForWhatsappChat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDv8HjZheHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install emoji\n",
        "!pip install git+https://github.com/emres/turkish-deasciifier.git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5--M3GFgjYO",
        "colab_type": "code",
        "outputId": "8d0f0791-285b-4ea5-b710-66fd8ef942d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "import pickle\n",
        "from google.colab import files\n",
        "from preprocess import preProcessing\n",
        "from gensim.models import TfidfModel, LdaModel, CoherenceModel\n",
        "from gensim.corpora import Dictionary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4y58F2Wg_9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ccAw1Xg0h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing = preProcessing()\n",
        "df = preprocessing.process('/content',False, False, True)\n",
        "dictionary = Dictionary(df['msg'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejXvy5y8va1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['datehour'] = df['date'].dt.hour\n",
        "df['dates'] = df['date'].dt.date\n",
        "df['datemins'] = df['date'].dt.minute\n",
        "df['decile'] = df['datemins'].apply(lambda x: int(x//10))\n",
        "new = df.groupby(['conv_name','datehour','decile', 'dates', 'group'])['msg'].sum().reset_index()\n",
        "new.tail(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjHeKTP90VOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['date'].dt.date"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2NaMhBPg11N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build b2w corpus\n",
        "bow_corpus = [dictionary.doc2bow(document) for document in df['msg']]\n",
        "\n",
        "#calculate tfidf\n",
        "tf_idf = TfidfModel(bow_corpus)\n",
        "corpus_tf_idf = tf_idf[bow_corpus]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwnvuZUjLCxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, doc in enumerate(df['msg']):\n",
        "  for token in doc:\n",
        "    if \"http\" in token:\n",
        "      print(doc, idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsDxEk0Xg3fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_models_with_coherence_score = {}\n",
        "for index in range(1, 10 + 1):\n",
        "    lda_model = LdaModel(corpus=corpus_tf_idf,\n",
        "                         num_topics=index,\n",
        "                         id2word=dictionary)\n",
        "\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model,\n",
        "                                         texts=df['msg'],\n",
        "                                         corpus=corpus_tf_idf,\n",
        "                                         coherence='c_v')\n",
        "    coherence_score = coherence_model_lda.get_coherence()\n",
        "    lda_models_with_coherence_score[coherence_score] = lda_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wig6XcYkQrBt",
        "colab_type": "code",
        "outputId": "6abd343c-7c70-4458-86bb-41542e5fb420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "lda_model = LdaModel(corpus=corpus_tf_idf,\n",
        "                         num_topics=150,\n",
        "                         id2word=dictionary,\n",
        "                         random_state=100,\n",
        "                         update_every=1,\n",
        "                         chunksize=100,\n",
        "                         passes=10,\n",
        "                         alpha=0.25,\n",
        "                         per_word_topics=True\n",
        "                     )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAu4auyXg6f_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lda_model = lda_models_with_coherence_score[max(lda_models_with_coherence_score)]\n",
        "\n",
        "with open('./lda_v2.model', \"wb\") as f:\n",
        " pickle.dump(lda_model, f)\n",
        " f.close()\n",
        "\n",
        "lda_model.show_topics(num_topics=150,num_words=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP1C2IBnDp7F",
        "colab_type": "code",
        "outputId": "fb8f6c0d-d311-4146-9c21-5da2fb39bbd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus_tf_idf))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=df['msg'], dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -120.2367816937994\n",
            "\n",
            "Coherence Score:  0.37224970630462595\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}